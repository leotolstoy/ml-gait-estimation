{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DoK10It3TUN2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')\n",
        "tf.test.is_built_with_cuda()\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import math\n",
        "from torch import nn, Tensor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
        "\n",
        "import random\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "01Xi5eEicpeM"
      },
      "outputs": [],
      "source": [
        "class ExobootDataset(Dataset):\n",
        "    \"\"\"Windowed Gait dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, gait_data, window_size=50, meas_scale=None, speed_scale=None, incline_scale=None, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            window_size (integer): size of the window to apply to the data\n",
        "            speed_scale (tuple, optional): A 2-tuple of the lower and upper bounds to scale the speed\n",
        "            incline_scale (tuple, optional): A 2-tuple of the lower and upper bounds to scale the incline\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.gait_data = gait_data\n",
        "        self.window_size = window_size\n",
        "        self.meas_scale = meas_scale\n",
        "        self.speed_scale = speed_scale\n",
        "        self.incline_scale = incline_scale\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.gait_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        if idx < self.window_size and idx >= 0:\n",
        "          # idx = len(self.gait_data)-1\n",
        "          idx = random.randint(self.window_size, len(self.gait_data)-1)\n",
        "          # print('saturating')\n",
        "\n",
        "\n",
        "        meas_idxs = [0,1,2,3,4,5,6]\n",
        "\n",
        "        #phase, speed, incline, is_stairs, is_moving\n",
        "        gait_state_idxs = [7,8,9,10,11]  \n",
        "        measurements = self.gait_data.iloc[idx-self.window_size:idx,meas_idxs].to_numpy()\n",
        "        \n",
        "        gait_states = self.gait_data.iloc[idx,gait_state_idxs].to_numpy()\n",
        "\n",
        "        # sample = {'meas': measurements, 'state': gait_states}\n",
        "        \n",
        "        if self.meas_scale is not None:\n",
        "            for i in range(len(meas_idxs)):\n",
        "                lb = self.meas_scale[i,0]\n",
        "                ub = self.meas_scale[i,1]\n",
        "                measurements[:,i] = ((1 - 0)/(ub - lb)) * (measurements[:,i] - lb)\n",
        "\n",
        "        if self.speed_scale:\n",
        "            lb = self.speed_scale[0]\n",
        "            ub = self.speed_scale[1]\n",
        "            gait_states[1] = ((1 - 0)/(ub - lb)) * (gait_states[1] - lb)\n",
        "\n",
        "        if self.incline_scale:\n",
        "            lb = self.incline_scale[0]\n",
        "            ub = self.incline_scale[1]\n",
        "            gait_states[2] = ((1 - 0)/(ub - lb)) * (gait_states[2] - lb)\n",
        "\n",
        "        \n",
        "        phase_as_angle = 2*np.pi*(gait_states[0]-0.5)\n",
        "        cp = np.cos(phase_as_angle)\n",
        "        sp = np.sin(phase_as_angle)\n",
        "        gait_states_new = np.zeros(gait_states.shape[0]+1,)\n",
        "        gait_states_new[0] = cp\n",
        "        gait_states_new[1] = sp\n",
        "        gait_states_new[2:] = gait_states[1:]\n",
        "        gait_states = gait_states_new\n",
        "\n",
        "        sample = {'meas': measurements, 'state': gait_states}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample, self.window_size)\n",
        "        \n",
        "        return sample\n",
        "        \n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample, window_size):\n",
        "        meas, state = sample['meas'], sample['state']\n",
        "       \n",
        "        meas = torch.from_numpy(meas).float()\n",
        "        state = torch.from_numpy(state).float()\n",
        "        state = torch.unsqueeze(state, dim=0)\n",
        "\n",
        "        return {'meas': meas, \n",
        "                'state': state}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN THIS TO SET UP COLAB\n",
        "ON_COLAB = True\n",
        "if ON_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_path = '/content/drive/MyDrive/Phase ML Data/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP5rhjrJs4Io",
        "outputId": "3e022392-efe0-4011-de24-02939185e43e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0TDj35NaeXVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5557826c-1430-47b1-ab65-ee2f759f48dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   foot_angles  foot_vel_angles  shank_angles  shank_vel_angles  \\\n",
            "0    27.703737       -22.952617     21.832302        -63.502207   \n",
            "1    25.742622       -65.596793     21.297953        -86.185133   \n",
            "2    24.324775      -100.132783     20.534140       -118.166841   \n",
            "3    24.324775      -119.138618     19.465094       -134.508304   \n",
            "4    23.294041       -35.650328     18.226569        -68.380255   \n",
            "\n",
            "   heel_acc_forward  heel_acc_up      dt  phase_ground_truth  \\\n",
            "0        -24.857099    -5.109614  0.0100            0.008016   \n",
            "1        -21.149576    -3.931122  0.0099            0.983308   \n",
            "2        -17.943035    -3.000270  0.0100            0.983729   \n",
            "3        -17.769398    -2.557593  0.0100            0.989832   \n",
            "4         13.277327    18.289915  0.0100            0.994453   \n",
            "\n",
            "   speed_ground_truth  incline_ground_truth  is_stairs  is_moving  \n",
            "0            0.670840             -1.419898        0.0        1.0  \n",
            "1            0.669866             -1.418597        0.0        1.0  \n",
            "2            0.671242             -1.417906        0.0        1.0  \n",
            "3            0.672204             -1.416767        0.0        1.0  \n",
            "4            0.670910             -1.415206        0.0        1.0  \n",
            "2916\n"
          ]
        }
      ],
      "source": [
        "window_size = 100\n",
        "meas_scale = np.array([[-69.35951035,  27.62815047],\\\n",
        "                            [-456.18013759,  401.13782617],\\\n",
        "                            [-63.71649984,  22.06632622],\\\n",
        "                            [-213.4786175,   396.93801619],\\\n",
        "                            [-35.26603985,  20.78473636],\\\n",
        "                            [-20.95456523,  14.63961137],\\\n",
        "                              [0,1]])\n",
        "speed_scale = (0,2)\n",
        "incline_scale = (-10,10)\n",
        "\n",
        "filename = 'exoboot_mars6.csv'\n",
        "\n",
        "if ON_COLAB:\n",
        "  filename = drive_path + filename\n",
        "\n",
        "exoboot_data = pd.read_csv(filename)\n",
        "\n",
        "print(exoboot_data.head() )\n",
        "print(len(exoboot_data))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dbSC9Jebqf9s"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The authors of the original transformer paper describe very succinctly what \n",
        "    the positional encoding layer does and why it is needed:\n",
        "    \n",
        "    \"Since our model contains no recurrence and no convolution, in order for the \n",
        "    model to make use of the order of the sequence, we must inject some \n",
        "    information about the relative or absolute position of the tokens in the \n",
        "    sequence.\" (Vaswani et al, 2017)\n",
        "    Adapted from: \n",
        "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        dropout: float=0.1, \n",
        "        max_seq_len: int=100, \n",
        "        d_model: int=512,\n",
        "        batch_first: bool=True,\n",
        "        ):\n",
        "\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            dropout: the dropout rate\n",
        "            max_seq_len: the maximum length of the input sequences\n",
        "            d_model: The dimension of the output of sub-layers in the model \n",
        "                     (Vaswani et al, 2017)\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.batch_first = batch_first\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.x_dim = 1 if batch_first else 0\n",
        "        pe = torch.zeros((1,max_seq_len,d_model))\n",
        "        self.register_buffer('pe', pe, persistent=False)\n",
        "\n",
        "        \n",
        "    def forward(self, x: Tensor, dts: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [batch_size, enc_seq_len, dim_val] or \n",
        "               [enc_seq_len, batch_size, dim_val]\n",
        "        \"\"\"\n",
        "        \n",
        "        #dts should be (batch_size, 50, 1)\n",
        "        #print('2')\n",
        "        #print(dts.shape)\n",
        "  \n",
        "        t_rel = torch.cumsum(torch.flip(dts, [1]), dim=1)\n",
        "\n",
        "        #flip order so most recent integrated is last\n",
        "        t_rel = torch.flip(t_rel, [1])\n",
        "        \n",
        "        #repeat integrated time across the embedding dimension\n",
        "        t_rel = t_rel.repeat(1, 1, self.d_model)\n",
        "\n",
        "        self.pe[0,:-1,:] = t_rel[0,1:,:]\n",
        "        \n",
        "        # self.pe = self.pe.to(device)\n",
        "        x = x + self.pe\n",
        "\n",
        "        return self.dropout(x)\n",
        "\n",
        "class GaitTransformer(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    This class implements a transformer model that can be used for times series\n",
        "    forecasting. This time series transformer model is based on the paper by\n",
        "    Wu et al (2020) [1]. The paper will be referred to as \"the paper\".\n",
        "    A detailed description of the code can be found in my article here:\n",
        "    https://towardsdatascience.com/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e\n",
        "    In cases where the paper does not specify what value was used for a specific\n",
        "    configuration/hyperparameter, this class uses the values from Vaswani et al\n",
        "    (2017) [2] or from PyTorch source code.\n",
        "    Unlike the paper, this class assumes that input layers, positional encoding \n",
        "    layers and linear mapping layers are separate from the encoder and decoder, \n",
        "    i.e. the encoder and decoder only do what is depicted as their sub-layers \n",
        "    in the paper. For practical purposes, this assumption does not make a \n",
        "    difference - it merely means that the linear and positional encoding layers\n",
        "    are implemented inside the present class and not inside the \n",
        "    Encoder() and Decoder() classes.\n",
        "    [1] Wu, N., Green, B., Ben, X., O'banion, S. (2020). \n",
        "    'Deep Transformer Models for Time Series Forecasting: \n",
        "    The Influenza Prevalence Case'. \n",
        "    arXiv:2001.08317 [cs, stat] [Preprint]. \n",
        "    Available at: http://arxiv.org/abs/2001.08317 (Accessed: 9 March 2022).\n",
        "    [2] Vaswani, A. et al. (2017) \n",
        "    'Attention Is All You Need'.\n",
        "    arXiv:1706.03762 [cs] [Preprint]. \n",
        "    Available at: http://arxiv.org/abs/1706.03762 (Accessed: 9 March 2022).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, \n",
        "        input_size: int,\n",
        "        num_predicted_features: int=4,\n",
        "        batch_first: bool=True,\n",
        "        dim_val: int=512,  \n",
        "        n_encoder_layers: int=4,\n",
        "        n_decoder_layers: int=4,\n",
        "        n_heads: int=8,\n",
        "        enc_seq_len: int=50,\n",
        "        dropout_encoder: float=0, \n",
        "        dropout_decoder: float=0,\n",
        "        dropout_pos_enc: float=0,\n",
        "        dropout_regression: float = 0,\n",
        "        dim_feedforward_encoder: int=128,\n",
        "        dim_feedforward_decoder: int=128,\n",
        "        ): \n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_size: int, number of input variables. 1 if univariate.\n",
        "            dec_seq_len: int, the length of the input sequence fed to the decoder\n",
        "            dim_val: int, aka d_model. All sub-layers in the model produce \n",
        "                     outputs of dimension dim_val\n",
        "            n_encoder_layers: int, number of stacked encoder layers in the encoder\n",
        "            n_heads: int, the number of attention heads (aka parallel attention layers)\n",
        "            dropout_encoder: float, the dropout rate of the encoder\n",
        "            dropout_pos_enc: float, the dropout rate of the positional encoder\n",
        "            dim_feedforward_encoder: int, number of neurons in the linear layer \n",
        "                                     of the encoder\n",
        "            num_predicted_features: int, the number of features you want to predict.\n",
        "                                    Most of the time, this will be 1 because we're\n",
        "                                    only forecasting FCR-N prices in DK2, but in\n",
        "                                    we wanted to also predict FCR-D with the same\n",
        "                                    model, num_predicted_features should be 2.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__() \n",
        "\n",
        "        #print(\"input_size is: {}\".format(input_size))\n",
        "        #print(\"dim_val is: {}\".format(dim_val))\n",
        "\n",
        "        # Creating the three linear layers needed for the model\n",
        "        self.embedding_layer = nn.Linear(\n",
        "            in_features=input_size, \n",
        "            out_features=dim_val \n",
        "            )\n",
        "\n",
        "\n",
        "        # The encoder layer used in the paper is identical to the one used by\n",
        "        # Vaswani et al (2017) on which the PyTorch module is based.\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=dim_val, \n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=dim_feedforward_encoder,\n",
        "            dropout=dropout_encoder,\n",
        "            activation='gelu',\n",
        "            batch_first=batch_first\n",
        "            )\n",
        "        \n",
        "        self.decoder_embedding_layer = nn.Linear(\n",
        "            in_features=num_predicted_features,\n",
        "            out_features=dim_val\n",
        "            )\n",
        "        \n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=dim_val,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=dim_feedforward_decoder,\n",
        "            dropout=dropout_decoder,\n",
        "            activation='gelu',\n",
        "            batch_first=batch_first\n",
        "            )\n",
        "\n",
        "        # Create positional encoder\n",
        "        self.positional_encoding_layer = PositionalEncoder(\n",
        "            d_model=dim_val,\n",
        "            dropout=dropout_pos_enc,\n",
        "            max_seq_len=enc_seq_len\n",
        "            )\n",
        "        \n",
        "        # Stack the encoder layers in nn.TransformerEncoder\n",
        "        # It seems the option of passing a normalization instance is redundant\n",
        "        # in my case, because nn.TransformerEncoderLayer per default normalizes\n",
        "        # after each sub-layer\n",
        "        # (https://github.com/pytorch/pytorch/issues/24930).\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            encoder_layer=encoder_layer,\n",
        "            num_layers=n_encoder_layers, \n",
        "            norm=None\n",
        "            )\n",
        "        \n",
        "        # Stack the decoder layers in nn.TransformerDecoder\n",
        "        # It seems the option of passing a normalization instance is redundant\n",
        "        # in my case, because nn.TransformerDecoderLayer per default normalizes\n",
        "        # after each sub-layer\n",
        "        # (https://github.com/pytorch/pytorch/issues/24930).\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            decoder_layer=decoder_layer,\n",
        "            num_layers=n_decoder_layers, \n",
        "            norm=None\n",
        "            )\n",
        "\n",
        "        # Regression head\n",
        "     \n",
        "        self.regression_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim_val),\n",
        "            nn.Dropout(dropout_regression),\n",
        "            nn.Linear(dim_val,  num_predicted_features)\n",
        "        )\n",
        "\n",
        "\n",
        "       \n",
        "  \n",
        "\n",
        "    def forward(self, src: Tensor, tgt: Tensor, dts : Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Returns a tensor of shape:\n",
        "        [target_sequence_length, batch_size, num_predicted_features]\n",
        "        \n",
        "        Args:\n",
        "            src: the encoder's output sequence. Shape: (S,E) for unbatched input, \n",
        "                 (S, N, E) if batch_first=False or (N, S, E) if \n",
        "                 batch_first=True, where S is the source sequence length, \n",
        "                 N is the batch size, and E is the number of features (1 if univariate)\n",
        "           \n",
        "           tgt: the sequence to the decoder. Shape: (T,E) for unbatched input, \n",
        "                 (T, N, E)(T,N,E) if batch_first=False or (N, T, E) if \n",
        "                 batch_first=True, where T is the target sequence length, \n",
        "                 N is the batch size, and E is the number of features (1 if univariate)\n",
        "            \n",
        "        \"\"\"\n",
        "\n",
        "        #print(\"From model.forward(): Size of src as given to forward(): {}\".format(src.size()))\n",
        "\n",
        "        # Pass throguh the input layer right before the encoder\n",
        "        src = self.embedding_layer(src) # src shape: [batch_size, src length, dim_val] regardless of number of input features\n",
        "        #print(\"From model.forward(): Size of src after input layer: {}\".format(src.size()))\n",
        "\n",
        "        src = self.positional_encoding_layer(src, dts) # src shape: [batch_size, src length, dim_val] regardless of number of input features\n",
        "\n",
        "        ## ENCODER\n",
        "      \n",
        "        src = self.encoder( # src shape: [batch_size, enc_seq_len, dim_val]\n",
        "            src=src\n",
        "            )\n",
        "       \n",
        "        decoder_output = self.decoder_embedding_layer(tgt) # tgt shape: [batch_size, target sequence length, dim_val] regardless of number of input features\n",
        "        \n",
        "        # Pass throguh decoder - output shape: [batch_size, target seq len, dim_val]\n",
        "        decoder_output = self.decoder(\n",
        "            tgt=decoder_output,\n",
        "            memory=src\n",
        "            )\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Pass through regression mapping\n",
        "        output = self.regression_head(decoder_output)\n",
        "        \n",
        "        # force the outputs of is_stairs and is_moving to be in [0,1] via sigmoid\n",
        "        output[:,:,4] = torch.sigmoid(output[:,:,4])\n",
        "        output[:,:,5] = torch.sigmoid(output[:,:,5])\n",
        "\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W0fxeTSf7KP",
        "outputId": "4a0bda08-7409-4ef7-96ca-ee19da4c6ada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 2,916 test points...\n",
            "Using GPU.\n",
            "Lowest Loss General: 0.16128962696268317\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    DONE PREDICTING\n"
          ]
        }
      ],
      "source": [
        "#Test model\n",
        "# Create the DataLoader.\n",
        "\n",
        "test_dataset = ExobootDataset(gait_data=exoboot_data,\n",
        "                                meas_scale=meas_scale,\n",
        "                                window_size = window_size,\n",
        "                                speed_scale = speed_scale,\n",
        "                                incline_scale = incline_scale,\n",
        "                                transform=ToTensor())\n",
        "\n",
        "BATCH_SIZE = 1024*4\n",
        "prediction_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,shuffle=False,num_workers=8)\n",
        "# prediction_dataloader = validation_dataloader\n",
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test points...'.format(len(test_dataset)))\n",
        "\n",
        "# Model parameters\n",
        "dim_val = 64 # This can be any value divisible by n_heads. 512 is used in the original transformer paper.\n",
        "n_heads = 8 # The number of attention heads (aka parallel attention layers). dim_val must be divisible by this number\n",
        "n_encoder_layers = 4 # Number of times the encoder layer is stacked in the encoder\n",
        "n_decoder_layers = 4 # Number of times the encoder layer is stacked in the encoder\n",
        "input_size = 7 # The number of input variables. 1 if univariate forecasting.\n",
        "enc_seq_len = 100 # length of input given to encoder. Can have any integer value.\n",
        "dec_seq_len = 1 # length of input given to decoder. Can have any integer value.\n",
        "\n",
        "dropout_encoder = 0.1\n",
        "dropout_decoder = 0.1\n",
        "dropout_pos_enc = 0.0\n",
        "dropout_regression = 0.1 \n",
        "dim_feedforward_encoder = 1024\n",
        "dim_feedforward_decoder = 1024\n",
        "\n",
        "num_predicted_features = 6 # The number of output variables. \n",
        "\n",
        "#INITIALIZE MODEL\n",
        "model = GaitTransformer(\n",
        "    dim_val=dim_val,\n",
        "    input_size=input_size, \n",
        "    n_encoder_layers=n_encoder_layers,\n",
        "    n_decoder_layers=n_decoder_layers,\n",
        "    n_heads=n_heads,\n",
        "    enc_seq_len=enc_seq_len,\n",
        "    dropout_encoder=dropout_encoder,\n",
        "    dropout_decoder=dropout_decoder,\n",
        "    dropout_pos_enc=dropout_pos_enc,\n",
        "    dropout_regression=dropout_regression,\n",
        "    num_predicted_features=num_predicted_features,\n",
        "    dim_feedforward_encoder=dim_feedforward_encoder,\n",
        "    dim_feedforward_decoder=dim_feedforward_decoder,\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU.\")\n",
        "else:\n",
        "    print(\"No GPU available, using the CPU instead.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "ON_COLAB = True\n",
        "model_nickname = 'keter'\n",
        "\n",
        "#LOAD IN CHECKPOINTS\n",
        "if ON_COLAB:\n",
        "  general_model_dir = f'{drive_path}/full_models/{model_nickname}/model_save_xval/'\n",
        "else:\n",
        "  general_model_dir = f'./full_models/{model_nickname}/model_save_xval/'\n",
        "\n",
        "checkpoint = torch.load(general_model_dir+'ml_gait_estimator_dec_best_model.tar',map_location=torch.device(device))\n",
        "g = checkpoint['model_state_dict']\n",
        "loss = checkpoint['loss']\n",
        "print(f'Lowest Loss General: {loss}')\n",
        "model.load_state_dict(g)\n",
        "\n",
        "# Put models in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "#Set up start of sequence token\n",
        "SOS_token = 100 * torch.ones(1, 1, num_predicted_features).to(device).requires_grad_(False)\n",
        "#Extract index for time steps\n",
        "DT_IDX = 6\n",
        "\n",
        "def phase_dist(phase_a, phase_b):\n",
        "    \"\"\"computes a distance that accounts for the modular arithmetic of phase\n",
        "    and guarantees that the output is between 0 and .5\n",
        "    \n",
        "    Args:\n",
        "        phase_a (float): a phase between 0 and 1\n",
        "        phase_b (float): a phase between 0 and 1\n",
        "    \n",
        "    Returns:\n",
        "        dist_prime: the difference between the phases, modulo'd between 0 and 0.5\n",
        "    \"\"\"\n",
        "    if isinstance(phase_a, np.ndarray):\n",
        "        dist_prime = (phase_a-phase_b)\n",
        "        dist_prime[dist_prime > 0.5] = 1-dist_prime[dist_prime > 0.5]\n",
        "\n",
        "        dist_prime[dist_prime < -0.5] = -1-dist_prime[dist_prime < -0.5]\n",
        "\n",
        "    else:\n",
        "        dist_prime = (phase_a-phase_b)\n",
        "        if dist_prime > 0.5:\n",
        "            dist_prime = 1-dist_prime\n",
        "\n",
        "        elif dist_prime < -0.5:\n",
        "            dist_prime = -1-dist_prime\n",
        "    return dist_prime\n",
        "\n",
        "\n",
        "def unscale_gait_state(gait_state_vec, speed_scale, incline_scale):\n",
        "    rows, cols = gait_state_vec.shape\n",
        "    # print(gait_state_vec.shape)\n",
        "    gait_state_unscaled = np.zeros((rows,cols-1))\n",
        "    \n",
        "    cp = gait_state_vec[:,0]\n",
        "    sp = gait_state_vec[:,1]\n",
        "    \n",
        "    #undo the trig on phase\n",
        "    x = np.arctan2(sp,cp)\n",
        "    phase_p = ((x)/(2*np.pi)) + 0.5\n",
        "    \n",
        "    gait_state_unscaled[:,0] = phase_p\n",
        "    \n",
        "    #unscale speed\n",
        "    speed_lb = speed_scale[0]\n",
        "    speed_ub = speed_scale[1]\n",
        "    speed_unscaled = (gait_state_vec[:,2] * (speed_ub - speed_lb)) + speed_lb\n",
        "    gait_state_unscaled[:,1] = speed_unscaled\n",
        "    \n",
        "    #unscale incline\n",
        "    incline_lb = incline_scale[0]\n",
        "    incline_ub = incline_scale[1]\n",
        "    incline_unscaled = (gait_state_vec[:,3] * (incline_ub - incline_lb)) + incline_lb\n",
        "    gait_state_unscaled[:,2] = incline_unscaled\n",
        "    \n",
        "    #add rest of gait state variables\n",
        "    gait_state_unscaled[:,3:] = gait_state_vec[:,4:]\n",
        "    \n",
        "    return gait_state_unscaled\n",
        "    \n",
        "# Predict \n",
        "print(len(prediction_dataloader))\n",
        "for batch in prediction_dataloader:\n",
        "\n",
        "    b_input = batch['meas'].to(device)\n",
        "    b_state = batch['state'].to(device)\n",
        "    \n",
        "    #truncate booleans\n",
        "    # b_state = b_state[:,:,:4]\n",
        "        \n",
        "    tgt = SOS_token.repeat(b_state.shape[0], 1, 1)\n",
        "    dts = b_input[:,:,DT_IDX]\n",
        "    dts = torch.unsqueeze(dts, dim=-1)\n",
        "\n",
        "\n",
        "    # Telling the model not to compute or store gradients, saving memory and \n",
        "    # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input,tgt, dts)\n",
        "\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    outputs = outputs.detach().to('cpu').numpy()\n",
        "    b_state = b_state.to('cpu').numpy()\n",
        "  \n",
        "    # Store predictions and true labels\n",
        "    outputs = np.squeeze(outputs, axis=1)\n",
        "    b_state = np.squeeze(b_state, axis=1)\n",
        "    \n",
        "    # print(outputs.shape)\n",
        "    \n",
        "    #unscale\n",
        "    outputs = unscale_gait_state(outputs, speed_scale, incline_scale)\n",
        "    b_state = unscale_gait_state(b_state, speed_scale, incline_scale)\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.extend(outputs.tolist())\n",
        "    true_labels.extend(b_state.tolist())\n",
        "\n",
        "print('    DONE PREDICTING')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "#generate losses for general model\n",
        "phase_losses = np.sqrt(phase_dist(predictions[:,0], true_labels[:,0])**2)\n",
        "speed_losses = np.sqrt((predictions[:,1] - true_labels[:,1])**2)\n",
        "incline_losses = np.sqrt((predictions[:,2] - true_labels[:,2])**2)\n",
        "is_stairs_accuracy = np.sum(np.round(true_labels[:,3]) == np.round(predictions[:,3]))/len(true_labels[:,3])\n",
        "is_moving_accuracy = np.sum(np.round(true_labels[:,4]) == np.round(predictions[:,4]))/len(true_labels[:,4])\n",
        "print(predictions.shape)\n",
        "\n",
        "\n",
        "print(\"=\"*30)\n",
        "print('General Model')\n",
        "print(f'Phase Losses: {np.mean(phase_losses):.3f} +- {np.std(phase_losses):.3f}')\n",
        "print(f'Speed Losses: {np.mean(speed_losses):.3f} +- {np.std(speed_losses):.3f}')\n",
        "print(f'Incline Losses: {np.mean(incline_losses):.3f} +- {np.std(incline_losses):.3f}')\n",
        "\n",
        "print(f'Is Stairs Accuracy: {is_stairs_accuracy:.3f}')\n",
        "print(f'Is Moving Accuracy: {is_moving_accuracy:.3f}')\n",
        "\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(5,1,figsize=(20,12),sharex=True)\n",
        "axs[0].plot(predictions[:,0],'r',label='predict, general')\n",
        "axs[0].plot(true_labels[:,0],'b',label='actual')\n",
        "axs[0].legend()\n",
        "axs[0].set_ylabel('Phase')\n",
        "# axs[0].set_xlim([80,5000])\n",
        "\n",
        "\n",
        "axs[1].plot(predictions[:,1],'r')\n",
        "axs[1].plot(true_labels[:,1],'b',label='actual')\n",
        "axs[1].set_ylabel('Speed (m/s)')\n",
        "axs[1].set_ylim([0,2])\n",
        "\n",
        "\n",
        "axs[2].plot(predictions[:,2],'r')\n",
        "axs[2].plot(true_labels[:,2],'b',label='actual')\n",
        "axs[2].set_ylabel('Incline (deg)')\n",
        "# axs[2].set_ylim([-15,15])\n",
        "\n",
        "axs[3].plot(predictions[:,3],'r')\n",
        "axs[3].plot(true_labels[:,3],'b',label='actual')\n",
        "axs[3].set_ylabel('Is Stairs')\n",
        "axs[3].set_ylim([-0.2,1.2])\n",
        "\n",
        "axs[4].plot(predictions[:,4],'r')\n",
        "axs[4].plot(true_labels[:,4],'b',label='actual')\n",
        "axs[4].set_ylabel('Is Moving')\n",
        "axs[4].set_ylim([-0.2,1.2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tte0RUmwGzcP",
        "outputId": "dc7d24d1-5eaa-40df-f59e-dcfaf2243c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2916, 5)\n",
            "==============================\n",
            "General Model\n",
            "Phase Losses: 0.029 +- 0.026\n",
            "Speed Losses: 0.150 +- 0.110\n",
            "Incline Losses: 3.116 +- 3.104\n",
            "Is Stairs Accuracy: 0.849\n",
            "Is Moving Accuracy: 1.000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.2, 1.2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn0gYmJ3dSt8"
      },
      "outputs": [],
      "source": [
        "params = list(model.named_parameters())\n",
        "print('The model has {:} different named parameters.\\n'.format(len(params)))\n",
        "for p in params:\n",
        "    # print('p')\n",
        "    # print(p[0])\n",
        "    # print(p[1].data)\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        params = parameter.numel()\n",
        "        table.add_row([name, params])\n",
        "        total_params+=params\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "pytorch-gpu.1-12.m98",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m98"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}